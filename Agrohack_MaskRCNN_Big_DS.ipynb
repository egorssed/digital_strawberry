{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agrohack_MaskRCNN_Big_DS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ottogin/digital_strawberry/blob/dev_egor/Agrohack_MaskRCNN_Big_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQXAb9mcRXqN"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f78MeC3mDy65",
        "outputId": "7b01e542-02d8-4955-8bd4-8f2c07ce7949"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "!pip install tensorflow==2.4.1\n",
        "#!pip install keras==2.2.5\n",
        "\n",
        "#import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from copy import deepcopy\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "Folder='/content/drive/My Drive/Agrohack/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 15 kB/s \n",
            "\u001b[?25hCollecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 31.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.7.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 37.7 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68720 sha256=2c7f2bd226c8975d870f512543cb0bdb5a97e327f188abb41db2a04a4ee640cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, grpcio, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "Successfully installed flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMzDr8LGDgDo"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nWmy3oAXlk8"
      },
      "source": [
        "import cv2\n",
        "mask=cv2.imread('drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Data/StrawDI_Db1/train/label/2638.png')\n",
        "img=cv2.imread('drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Data/StrawDI_Db1/train/img/2638.png')\n",
        "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "hpQrL6lW01QC",
        "outputId": "8c84113c-b133-45ed-80a0-2c67121d24cb"
      },
      "source": [
        "plt.imshow(mask[:,:,0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f155a5e0710>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igy4ofF-_jHS"
      },
      "source": [
        "# Train Mask RCNN beagle based"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21nUE1yQ_v1b"
      },
      "source": [
        "dataset_dir='drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Data/StrawDI_Db1/'\n",
        "weights_dir='drive/MyDrive/Agrohack/Dataset_Mask_RCNN/MRCNN/mask_rcnn_coco.h5'\n",
        "script_dir='drive/MyDrive/Agrohack/Dataset_Mask_RCNN/fine-tune-MaskRcnn/beagle.py'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIc4QHsH_l_G"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhy-_EREEh9q"
      },
      "source": [
        "ROOT_DIR = os.path.abspath('drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/')\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "COCO_WEIGHTS_PATH = weights_dir\n",
        "\n",
        "sys.path.append(ROOT_DIR)\n",
        "\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib,utils"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_J1hJ06EORT"
      },
      "source": [
        "# Code for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHHXTpc_gi6Q"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VLt0rq7_mDz"
      },
      "source": [
        "class CustomConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy  dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"strawberry\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + beagle\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "\n",
        "\n",
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class CustomDataset(utils.Dataset):\n",
        "\n",
        "    def load_custom(self, dataset_dir, subset):\n",
        "        \"\"\"Load the beagle dataset.\n",
        "        dataset_dir: Root directory of the dataset.\n",
        "        subset: Subset to load: train or val\n",
        "        \"\"\"\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"strawberry\", 1, \"strawberry\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"test\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        for index_file,filename in tqdm(enumerate(os.listdir(os.path.join(dataset_dir,'img')))):\n",
        "            image_path = os.path.join(dataset_dir, 'img' ,filename)\n",
        "            mask_path= os.path.join(dataset_dir, 'label' ,filename)\n",
        "            image = skimage.io.imread(image_path)\n",
        "            mask= skimage.io.imread(mask_path)\n",
        "            height, width = image.shape[:2]\n",
        "            self.add_image(\n",
        "                \"strawberry\",  ## for a single class just add the name here\n",
        "                image_id=filename,  # use file name as a unique image id\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=mask)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        # If not a beagle dataset image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"strawberry\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "        mask_image = info[\"polygons\"]\n",
        "        detected_ids=np.unique(mask_image)[1:]\n",
        "\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(detected_ids)],\n",
        "                        dtype=np.uint8)\n",
        "\n",
        "        for i,id in enumerate(detected_ids):\n",
        "            mask[:,:,i][mask_image==id]=1\n",
        "\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"strawberry\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "Checkpoints_Folder='drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Data/Checkpoints/'\n",
        "def on_epoch_end(epoch=0, logs=''):\n",
        "    Model_folder=Checkpoints_Folder+'/Model_epoch_{}.h5'.format(epoch)\n",
        "    model.save_weights(Model_folder)\n",
        "\n",
        "checkpoint_callback=LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "def train(model,config):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = CustomDataset()\n",
        "    dataset_train.load_custom(dataset_dir, \"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = CustomDataset()\n",
        "    dataset_val.load_custom(dataset_dir, \"test\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    # *** This training schedule is an example. Update to your needs ***\n",
        "    # Since we're using a very small dataset, and starting from\n",
        "    # COCO trained weights, we don't need to train too long. Also,\n",
        "    # no need to train all layers, just the heads should do it.\n",
        "    print(\"Training network heads\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=100,\n",
        "                layers='heads')\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def color_splash(image, mask):\n",
        "    \"\"\"Apply color splash effect.\n",
        "    image: RGB image [height, width, 3]\n",
        "    mask: instance segmentation mask [height, width, instance count]\n",
        "\n",
        "    Returns result image.\n",
        "    \"\"\"\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\n",
        "    # has 3 RGB channels, though.\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "    # We're treating all instances as one, so collapse the mask into one layer\n",
        "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "    # Copy color pixels from the original color image where mask is set\n",
        "    if mask.shape[0] > 0:\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
        "    else:\n",
        "        splash = gray\n",
        "    return splash\n",
        "\n",
        "\n",
        "def detect_and_color_splash(model, image_path=None, video_path=None):\n",
        "    assert image_path or video_path\n",
        "\n",
        "    # Image or video?\n",
        "    if image_path:\n",
        "        # Run model detection and generate the color splash effect\n",
        "        print(\"Running on {}\".format(args.image))\n",
        "        # Read image\n",
        "        image = skimage.io.imread(args.image)\n",
        "        # Detect objects\n",
        "        r = model.detect([image], verbose=1)[0]\n",
        "        # Color splash\n",
        "        splash = color_splash(image, r['masks'])\n",
        "        # Save output\n",
        "        file_name = \"splash_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
        "        skimage.io.imsave(file_name, splash)\n",
        "    elif video_path:\n",
        "        import cv2\n",
        "        # Video capture\n",
        "        vcapture = cv2.VideoCapture(video_path)\n",
        "        width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = vcapture.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Define codec and create video writer\n",
        "        file_name = \"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\n",
        "        vwriter = cv2.VideoWriter(file_name,\n",
        "                                  cv2.VideoWriter_fourcc(*'MJPG'),\n",
        "                                  fps, (width, height))\n",
        "\n",
        "        count = 0\n",
        "        success = True\n",
        "        while success:\n",
        "            print(\"frame: \", count)\n",
        "            # Read next image\n",
        "            success, image = vcapture.read()\n",
        "            if success:\n",
        "                # OpenCV returns images as BGR, convert to RGB\n",
        "                image = image[..., ::-1]\n",
        "                # Detect objects\n",
        "                r = model.detect([image], verbose=0)[0]\n",
        "                # Color splash\n",
        "                splash = color_splash(image, r['masks'])\n",
        "                # RGB -> BGR to save image to video\n",
        "                splash = splash[..., ::-1]\n",
        "                # Add image to video writer\n",
        "                vwriter.write(splash)\n",
        "                count += 1\n",
        "        vwriter.release()\n",
        "    print(\"Saved to \", file_name)\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_11_hsHCG9RC"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7izRqvlG8CU",
        "outputId": "84c1b90b-d3f6-48f6-d968-773c01d8358f"
      },
      "source": [
        "!ls 'drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330/mask_rcnn_strawberry_0010.h5'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330/mask_rcnn_strawberry_0010.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7VK862C_mFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "741eb145-fa42-434f-da0c-99f25ea44a80"
      },
      "source": [
        "    command='train'\n",
        "\n",
        "    if command == \"train\":\n",
        "        config = CustomConfig()\n",
        "    else:\n",
        "        class InferenceConfig(CustomConfig):\n",
        "            # Set batch size to 1 since we'll be running inference on\n",
        "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "            GPU_COUNT = 1\n",
        "            IMAGES_PER_GPU = 1\n",
        "        config = InferenceConfig()\n",
        "    config.display()\n",
        "\n",
        "    # Create model\n",
        "    if command == \"train\":\n",
        "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "    else:\n",
        "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "    weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "    # Load weights\n",
        "    print(\"Loading weights \", weights_path)\n",
        "    \n",
        "    # Exclude the last layers because they require a matching\n",
        "    # number of classes\n",
        "\n",
        "    '''\n",
        "    model.load_weights(weights_path, by_name=True, exclude=[\n",
        "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "    '''\n",
        "\n",
        "    model.load_weights('drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330/mask_rcnn_strawberry_0010.h5', by_name=True)\n",
        "\n",
        "    # Train or evaluate\n",
        "    if command == \"train\":\n",
        "        train(model,config)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           strawberry\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "Loading weights  drive/MyDrive/Agrohack/Dataset_Mask_RCNN/MRCNN/mask_rcnn_coco.h5\n",
            "Re-starting from epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2800it [51:06,  1.10s/it]\n",
            "200it [03:45,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training network heads\n",
            "\n",
            "Starting at epoch 10. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330/mask_rcnn_strawberry_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "rpn_model              (Functional)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 11/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFvq6KHXVFJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvwFAxpXXVIQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZwZrF9LXVM6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjieVZp9XVOm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUD4X7ibXVRd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUywutQ5Eu40",
        "outputId": "494478d6-1686-4911-b91f-d997845411b9"
      },
      "source": [
        "!ls 'drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330mask_rcnn_strawberry_0010.h5'"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330mask_rcnn_strawberry_0010.h5': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhd70C6UEu77"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikldAf_GEu-5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfRGi7V0Gbmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875e67e4-8e63-48f3-cbb0-e2c8a898b3de"
      },
      "source": [
        "from platform import python_version\n",
        "\n",
        "print(python_version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRua7pBu9E7a",
        "outputId": "474e5d71-9be4-466b-8432-05b157ca328f"
      },
      "source": [
        "!ls 'drive/MyDrive/Argohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/strawberry20211120T2330'"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'drive/MyDrive/Argohack': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znfFSqcAGbpT"
      },
      "source": [
        "model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvO7Hsg1_mKp"
      },
      "source": [
        "model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp2aAbbM_ffu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nemfMJuz9vQy"
      },
      "source": [
        "cp -R 'drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330/' 'drive/MyDrive/Agrohack/Dataset_Mask_RCNN/Mask-RCNN-leekunhee/logs/strawberry20211120T2330_backup'"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOJ7pa6R_HZU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "599U3IXZ_Hg6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl3UAUi__Hjc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-9haI739xgY",
        "outputId": "5e76d05d-6e86-4b98-e147-91e4ee780014"
      },
      "source": [
        "!ls 'drive/MyDrive/Argohack/Dataset_Mask_RCNN'"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'drive/MyDrive/Argohack/Dataset_Mask_RCNN': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLWM6eUv-AMn",
        "outputId": "54c6039c-2cd1-49a7-eb28-c72af9ae1c63"
      },
      "source": [
        "!ls 'drive/MyDrive/Agrohack/Dataset_Mask_RCNN'"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data\t\t       Mask-RCNN-TF2\t      StrawDI_Db1.zip\n",
            " fine-tune-MaskRcnn    MRCNN\n",
            " Mask-RCNN-leekunhee  'StrawDI_Db1 (1).zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igMiKtYw-cgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}